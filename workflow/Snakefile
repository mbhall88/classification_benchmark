import pandas as pd
from pathlib import Path
from humanfriendly import parse_size


configfile: "config/config.yaml"


WORKFLOW = Path("workflow").resolve()
CONFIG = Path("config").resolve()
RULES = WORKFLOW / "rules"
ENVS = WORKFLOW / "envs"
SCRIPTS = WORKFLOW / "scripts"
RESULTS = Path("results").resolve()
BENCH = RESULTS / "benchmark"
LOGS = Path("logs/rules").resolve()
CONTAINERS = config["containers"]
RESOURCES = Path("resources").resolve()
GB = 1_000

gramtools_lineages = pd.read_csv(config["gramtools_lineages"])
GRAMTOOLS_SAMPLES = sorted(list(gramtools_lineages["strain"]))

target_files = set()
for size in config["kraken_db_size"]:
    for d in config["kraken_wl_sizes"]:
        k = d["k"]
        l = d["l"]
        target_files.add(RESULTS / f"kraken/k{k}/l{l}/{size}/db")
        target_files.add(
            RESULTS / f"dehumanise/kraken/classify/k{k}l{l}/metagenome.ont.k2"
        )

kraken_libs = ["bacteria", "archaea", "viral", "human", "plasmid"]

for lib in kraken_libs:
    target_files.add(RESULTS / f"kraken/db/library/{lib}/library.fna")


target_files.add(RESULTS / "simulate/reads/metagenome.ont.fq.gz")
target_files.add(RESULTS / "db/minimap2/db.fa.gz.map-ont.mmi")
target_files.add(RESULTS / "dehumanise/minimap2/metagenome.aln.ont.paf")
target_files.add(RESULTS / "dehumanise/sra/metagenome.scrubbed.ont.fq.gz")
target_files.add(RESULTS / "simulate/references/Mycobacteria.fa.gz")
target_files.add(RESULTS / "assess/acc2tax.tsv")


localrules:
    all,


rule all:
    input:
        target_files,


include: RULES / "db.smk"
include: RULES / "simulate.smk"
include: RULES / "dehumanise.smk"
include: RULES / "assess.smk"
